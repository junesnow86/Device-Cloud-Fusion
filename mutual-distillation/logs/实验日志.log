怀疑是 CIFAR-100 的样本数太少了，小型模型的性能都很难提高。

2024.3.24
根据 main03241046.log 和 main03241258.log 的结果，双向蒸馏在端侧模型上取得了一定的效果，三个参与方中有两个参与方的性能得到了提高，但是一个参与方的性能下降了。
而有一个很奇怪的点是云侧模型在蒸馏后准确率降为 0.0，这个问题需要进一步排查。

2024.3.25
后面打算在设备到云的蒸馏时考虑数据筛选，这样的话分别使用 CIFAR-10 和 Caltech-101 作为设备数据集和云数据集就不自然。打算使用 ImageNet，划分成云数据集和设备数据集。
还有前面写的代码里，从云到设备的蒸馏是不对的，因为云模型不能直接下载到端。而且蒸馏还写成调用`train`了。。。

2024.4.10
云端数据集使用的是CIFAR-10，设备端数据集使用的是FashionMNIST，在进行设备端本地微调后，设备端的三个小模型在云端测试集上表现为10%左右的准确率（相当于随机选），而在进行本地微调之前，准确率有70%以上。
这是可以理解的，因为设备端小模型的分类器层对应的标签语义是FashionMNIST的10个标签。

而经过实验验证，在ResNet-18黑盒的基础上，外接一层线性层分类器，前后性能表现相差无几（0.8005 v.s. 0.7909）。
因此，可以考虑添加外置的dataset-specific classifier来尝试解决上述问题。

custom cloud resnet18 pretrained: 0.8025
custom distill mobilenet pretrained: 0.7225
custom distill shufflenet pretrained: 0.7234
custom distill squeeze pretrained: 0.7031

2024.4.14
pretrained custom mobilenet test on FashionMNIST: 0.1112
fine-tuned custom mobilenet test on FashionMNIST: 0.7809

pretrained custom shufflenet test on FashionMNIST: 0.1004
fine-tuned custom shufflenet test on FashionMNIST: 0.8526

pretrained custom squeezenet test on FashionMNIST: 0.1110
fine-tuned custom squeezenet test on FashionMNIST: 0.8672

---------------------------------------------------------
使用fine-tuned backbone + pretrained classifier在CIFAR-10上进行测试，准确率只有0.1，也就是说保留pretrained classifier没有作用。
微调后的backbone起决定性作用，会导致小模型遗忘预训练数据集的特征提取能力。
---------------------------------------------------------
验证ensemble的提升效果：
pretrained
Model 0 accuracy: 0.7292                                                                                                                                                                                                                                
Model 1 accuracy: 0.7289
Model 2 accuracy: 0.7276
Ensemble accuracy: 0.7855
Ensemble vote accuracy: 0.7620

fine-tuned
Model 0 fine-tune accuracy: 0.8048                                                                                                                                                                                                                      
Model 1 fine-tune accuracy: 0.8608
Model 2 fine-tune accuracy: 0.8704
Ensemble fine-tune accuracy: 0.8875
Ensemble vote fine-tune accuracy: 0.8829
