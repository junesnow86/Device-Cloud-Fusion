怀疑是 CIFAR-100 的样本数太少了，小型模型的性能都很难提高。

2024.3.24
根据 main03241046.log 和 main03241258.log 的结果，双向蒸馏在端侧模型上取得了一定的效果，三个参与方中有两个参与方的性能得到了提高，但是一个参与方的性能下降了。
而有一个很奇怪的点是云侧模型在蒸馏后准确率降为 0.0，这个问题需要进一步排查。

2024.3.25
后面打算在设备到云的蒸馏时考虑数据筛选，这样的话分别使用 CIFAR-10 和 Caltech-101 作为设备数据集和云数据集就不自然。打算使用 ImageNet，划分成云数据集和设备数据集。
还有前面写的代码里，从云到设备的蒸馏是不对的，因为云模型不能直接下载到端。而且蒸馏还写成调用`train`了。。。

2024.4.10
云端数据集使用的是CIFAR-10，设备端数据集使用的是FashionMNIST，在进行设备端本地微调后，设备端的三个小模型在云端测试集上表现为10%左右的准确率（相当于随机选），而在进行本地微调之前，准确率有70%以上。
这是可以理解的，因为设备端小模型的分类器层对应的标签语义是FashionMNIST的10个标签。

而经过实验验证，在ResNet-18黑盒的基础上，外接一层线性层分类器，前后性能表现相差无几（0.8005 v.s. 0.7909）。
因此，可以考虑添加外置的dataset-specific classifier来尝试解决上述问题。
