Files already downloaded and verified
Files already downloaded and verified
>>> Start training cloud model...
Epoch 1: training loss=2.3313625502207924, validation loss=2.3071586042642593
Epoch 2: training loss=2.3036483999282593, validation loss=2.284870907664299
Epoch 3: training loss=2.2726712643154086, validation loss=2.265461429953575
Epoch 4: training loss=2.2455113199022083, validation loss=2.2294392436742783
Epoch 5: training loss=2.1948968531593445, validation loss=2.1776637732982635
Epoch 6: training loss=2.1336325917925154, validation loss=2.1511744260787964
Epoch 7: training loss=2.0874719014243475, validation loss=2.136983871459961
Epoch 8: training loss=2.0457656402436513, validation loss=2.1131412237882614
Epoch 9: training loss=1.9971983830134075, validation loss=2.0695427283644676
Epoch 10: training loss=1.9502693622831315, validation loss=2.0283710062503815
Epoch 11: training loss=1.881454274767921, validation loss=2.0056669116020203
Epoch 12: training loss=1.819127120668926, validation loss=2.0216601490974426
Epoch 13: training loss=1.7699865443365914, validation loss=2.0247922018170357
Epoch 14: training loss=1.719283039607699, validation loss=2.0322140008211136
Early stop at epoch 14.
>>> Start training party A model...
Epoch 1: training loss=2.160096253909118, validation loss=2.018004054754553
Epoch 2: training loss=1.8729813796408632, validation loss=1.7061526775360107
Epoch 3: training loss=1.5800392378306558, validation loss=1.4282717822303235
Epoch 4: training loss=1.3639041096606153, validation loss=1.3296935205728235
Epoch 5: training loss=1.293028806540983, validation loss=1.2841671638085808
Epoch 6: training loss=1.2420175629304655, validation loss=1.3386382687259728
Epoch 7: training loss=1.3314963393177546, validation loss=1.2131159674953407
Epoch 8: training loss=1.176818700546914, validation loss=1.1443606254080652
Epoch 9: training loss=1.1076161305532388, validation loss=1.1078931403831698
Epoch 10: training loss=1.053829459856588, validation loss=1.1215280814909598
Epoch 11: training loss=1.2996279318281945, validation loss=1.21023484015129
Epoch 12: training loss=1.2606759709669344, validation loss=1.2922740721366774
Early stop at epoch 12.
>>> Start training party B model...
Epoch 1: training loss=2.1383707793891853, validation loss=1.9569404830395336
Epoch 2: training loss=1.6503934412137837, validation loss=1.318774920114329
Epoch 3: training loss=1.142501618422515, validation loss=1.0362764848789698
Epoch 4: training loss=0.955327275374257, validation loss=0.9205989627770974
Epoch 5: training loss=0.8524680188361634, validation loss=0.859733006484072
Epoch 6: training loss=0.7712527053787354, validation loss=0.8087788345948072
Epoch 7: training loss=0.7008591058617788, validation loss=0.760558479268786
Epoch 8: training loss=0.6523697429092218, validation loss=0.7321409515931573
Epoch 9: training loss=0.595772219148088, validation loss=0.7355498335730861
Epoch 10: training loss=0.5633549121677452, validation loss=0.7057336778707908
Epoch 11: training loss=0.5253460284665967, validation loss=0.7137463984774871
Epoch 12: training loss=0.4942243143070674, validation loss=0.7017359198398994
Epoch 13: training loss=0.4627836391541129, validation loss=0.730121008527111
Epoch 14: training loss=0.4325158857073344, validation loss=0.7183232702000041
Epoch 15: training loss=0.4132004309419199, validation loss=0.7388871486338091
Early stop at epoch 15.
>>> Start distillation from party A to cloud...
Epoch 1: training loss=0.21046312758368804, validation loss=0.315450798877528
Epoch 2: training loss=0.17787466206132097, validation loss=0.7761857308132548
Epoch 3: training loss=1.0878456147215891, validation loss=1.4949087458597103
Epoch 4: training loss=0.4234219930590467, validation loss=2.263220985170821
Early stop at epoch 4.
>>> Start distillation from party B to cloud...
Epoch 1: training loss=54.332025061262414, validation loss=39.86265252341687
Epoch 2: training loss=34.51193891011231, validation loss=33.39356460034008
Epoch 3: training loss=29.715697234404004, validation loss=29.687838540950292
Epoch 4: training loss=26.996593306250606, validation loss=27.536110676510233
Epoch 5: training loss=25.45324591711058, validation loss=26.281237105248678
Epoch 6: training loss=24.500852026837936, validation loss=25.5337907495633
Epoch 7: training loss=23.993023507138517, validation loss=25.08839252633108
Epoch 8: training loss=23.665762356832516, validation loss=24.816560516894704
Epoch 9: training loss=23.511778202462704, validation loss=24.6493773796189
Epoch 10: training loss=23.39572695130152, validation loss=24.544065354575572
>>> Start distillation from cloud to party A...
Epoch 1: training loss=212.9225171136518, validation loss=74.89873209133954
Epoch 2: training loss=78.57249538611013, validation loss=139.7498930810203
Epoch 3: training loss=79.2065843014007, validation loss=92.91311581034056
Epoch 4: training loss=83.10082564117215, validation loss=63.72486968779228
Epoch 5: training loss=68.37925353625143, validation loss=61.05962362423749
Epoch 6: training loss=63.164361020351976, validation loss=63.77607453037316
Epoch 7: training loss=65.31651337265123, validation loss=61.80181229282433
Epoch 8: training loss=62.09254655094011, validation loss=57.49752826422033
Epoch 9: training loss=61.98321259951761, validation loss=57.22655896737542
Epoch 10: training loss=60.156775503293844, validation loss=55.22514104171538
>>> Start distillation from cloud to party B...
Epoch 1: training loss=186.01027059893235, validation loss=62.261674585476726
Epoch 2: training loss=67.70359060950312, validation loss=60.75806770861988
Epoch 3: training loss=63.61342996232053, validation loss=47.983240288747865
Epoch 4: training loss=55.845139523769944, validation loss=62.10687314960319
Epoch 5: training loss=52.93007018041949, validation loss=51.19639582029531
Epoch 6: training loss=46.35948258257927, validation loss=51.36552603815643
Early stop at epoch 6.
Cloud model accuracy: 0.2880
Party A model accuracy: 0.2147
Party B model accuracy: 0.3715
Cloud model accuracy after distillation from party A: 0.1065
Cloud model accuracy after distillation from party B: 0.0970
Party A accuracy after distillation from cloud: 0.1000
Party B accuracy after distillation from cloud: 0.1001

Comments:
相互蒸馏的做法似乎是dead end。