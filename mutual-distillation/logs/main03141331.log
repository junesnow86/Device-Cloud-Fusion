Files already downloaded and verified
Files already downloaded and verified
>>> Start training cloud model...
Epoch 1: training loss=0.7526222763332069, validation loss=0.6444477923214436
Epoch 2: training loss=0.55882428639324, validation loss=0.4921270087361336
Epoch 3: training loss=0.4973477913555524, validation loss=0.48665478080511093
Epoch 4: training loss=0.4684615450125214, validation loss=0.47477021627128124
Epoch 5: training loss=0.435207558650497, validation loss=0.43851297721266747
Epoch 6: training loss=0.3975177363935092, validation loss=0.42871175333857536
Epoch 7: training loss=0.36565685261648595, validation loss=0.3818541597574949
Epoch 8: training loss=0.3217166575556951, validation loss=0.4026312753558159
Epoch 9: training loss=0.28804946907445894, validation loss=0.4156772755086422
Epoch 10: training loss=0.2650541348237518, validation loss=0.38170310854911804
Epoch 11: training loss=0.24476106390885427, validation loss=0.38893897272646427
Epoch 12: training loss=0.20296453531329514, validation loss=0.4546758010983467
Epoch 13: training loss=0.17809304357209105, validation loss=0.4461654322221875
Early stop at epoch 13.
>>> Start training party A model...
Epoch 1: training loss=2.109490033582593, validation loss=1.8988439477980137
Epoch 2: training loss=1.6975794637456854, validation loss=1.5151220597326756
Epoch 3: training loss=1.420349767444827, validation loss=1.3462903499603271
Epoch 4: training loss=1.29334948671625, validation loss=1.2613148987293243
Epoch 5: training loss=1.2213449499285813, validation loss=1.217565380036831
Epoch 6: training loss=1.1823374954521233, validation loss=1.2023315727710724
Epoch 7: training loss=1.1516223558297394, validation loss=1.1849729008972645
Epoch 8: training loss=1.1242242345573208, validation loss=1.1809929311275482
Epoch 9: training loss=1.0918734661230804, validation loss=1.1784666702151299
Epoch 10: training loss=1.0716475681632969, validation loss=1.1679035983979702
Epoch 11: training loss=1.0443034142467147, validation loss=1.17216083034873
Epoch 12: training loss=1.0283861143369202, validation loss=1.174800330772996
Epoch 13: training loss=1.0004267741179635, validation loss=1.1748200114816427
Early stop at epoch 13.
>>> Start training party B model...
Epoch 1: training loss=2.029020961294783, validation loss=1.6994146183133125
Epoch 2: training loss=1.261082610339983, validation loss=0.9863382317125797
Epoch 3: training loss=0.8604760935120549, validation loss=0.8040954899042845
Epoch 4: training loss=0.6805581046757123, validation loss=0.6614270936697721
Epoch 5: training loss=0.5647525776785316, validation loss=0.5830341707915068
Epoch 6: training loss=0.4784547594105098, validation loss=0.5338159035891294
Epoch 7: training loss=0.42349813270864756, validation loss=0.5135495131835341
Epoch 8: training loss=0.38223885020888443, validation loss=0.48276785016059875
Epoch 9: training loss=0.34349442088434884, validation loss=0.4634579182602465
Epoch 10: training loss=0.318759708381291, validation loss=0.464162933640182
Epoch 11: training loss=0.28442509369330204, validation loss=0.4660584796220064
Epoch 12: training loss=0.26813008929503723, validation loss=0.4548996798694134
Epoch 13: training loss=0.24569858256595353, validation loss=0.4686558609828353
Epoch 14: training loss=0.22904966947298946, validation loss=0.4752520425245166
Epoch 15: training loss=0.2089283590119147, validation loss=0.4911215426400304
Early stop at epoch 15.
>>> Start distillation from party A to cloud...
Epoch 1: training loss=0.16780371726193327, validation loss=0.07736542483326048
Epoch 2: training loss=0.07162769815177782, validation loss=0.05496842321008444
Epoch 3: training loss=0.05708051004598961, validation loss=0.04636248492170125
Epoch 4: training loss=0.050469684328698944, validation loss=0.042229331214912236
Epoch 5: training loss=0.04719478899203505, validation loss=0.03985068533802405
Epoch 6: training loss=0.044533395135761995, validation loss=0.037978951761033386
Epoch 7: training loss=0.04298757351538603, validation loss=0.03681913740001619
Epoch 8: training loss=0.04170098179515372, validation loss=0.036139597184956074
Epoch 9: training loss=0.04089613443782143, validation loss=0.036909758870024234
Epoch 10: training loss=0.04018443851262754, validation loss=0.03555104701081291
>>> Start distillation from party B to cloud...
Epoch 1: training loss=1.3114249653427312, validation loss=0.9435252193361521
Epoch 2: training loss=0.9670841784764689, validation loss=0.8847353495657444
Epoch 3: training loss=0.9081044027991328, validation loss=0.8658143784850836
Epoch 4: training loss=0.8707361749723448, validation loss=0.8545746840536594
Epoch 5: training loss=0.8376794724811053, validation loss=0.8340174984186888
Epoch 6: training loss=0.8092514927505602, validation loss=0.8337977025657892
Epoch 7: training loss=0.7808962394582465, validation loss=0.822059728205204
Epoch 8: training loss=0.7380825357234224, validation loss=0.8248525280505419
Epoch 9: training loss=0.7059014058070825, validation loss=0.8102082721889019
Epoch 10: training loss=0.684387263888163, validation loss=0.8504581991583109
Cloud model accuracy: 0.1708
Party A model accuracy: 0.1963
Party B model accuracy: 0.3423
Cloud model accuracy after distillation from party A: 0.0939
Cloud model accuracy after distillation from party B: 0.1030

Comments:
蒸馏后测试性能变差了，可能有几方面原因：
1. 模型学坏了
2. 云侧的特征提取模块和分类器没有学到新知识

下一步：
1. 从云到端的蒸馏，使用什么数据？
    1. 用端侧自己的数据，但是那样学不到其他参与方的数据特征；但是一个参与方的目的就只是优化自己的个性化模型
